\chapter{蒙特卡洛方法}
\label{chap:17}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%% author:kiseliu  %%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%% part17.0-17.3   %%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{采样和蒙特卡罗方法}
随机化算法可以分成大致两类：拉斯维加斯算法和蒙特卡罗算法。拉斯维加斯算法总是准确地返回正确答案(或者报告失败)。这类算法假设随机量的资源，通常是内存或者时间。相反，蒙特卡罗算法返回答案时会带有随机量的错误。错误量通常可以通过扩展更多的资源(通常是运行时间和内存)被减少。对任意固定的计算方案，蒙特卡罗都可以给出一个近似回答。

机器学习领域中的许多问题都很困难，除了精确的确定性算法和拉斯维加斯算法，我们不能期待获得这些困难问题的精确答案。相反，我们必须使用确定性的近似算法或者蒙特卡罗近似，这两种方法在机器学习中是广泛存在的。本章，我们将讨论蒙特卡罗方法。

\subsection{采样和蒙特卡罗方法}
许多用于实现机器学习目标的重要技术都是基于从一些概率分布中抽取样本，然后用这些样本进行一定理想数量的蒙特卡罗估计。

\subsection{为什么采样？}
我们想要从概率分布中抽取样本有许多原因。采样用更少的代价，提供了一种灵活的方法来近似许多加和和积分。有时候我们使用采样来加速代价昂贵但是容易处理的加和，比如我们使用minibatches对整个训练代价子采样的情况。在其他情况，我们的学习算法需要逼近一个不容易处理的加和或者积分，比如对数模型的对数配分函数(log partition function)的梯度。在许多其他情况下，在我们想训练一个可以从训练分布中采样的模型的意义上，采样确实是我们的目标。


\subsection{蒙特卡罗采样的基本知识}
 当加和或者积分不能准确地被计算出来(比如，该加和具有指数级别数量的项，并且没有精确的简化)，我们经常会使用蒙特卡罗采样来逼近它。其思想是将加和或者积分看作是某种分布下的期望，然后通过相应的平均来近似该期望。令
 $$ s = \sum _{ x }^{  }{ p(\bm{x})f(\bm{x}) ={ E }_{ p }[f(\textbf{x})] }\eqno{(17.1)} $$
或者
 $$ s=\int { p(\bm{x})f(\bm{x})d\bm{x}= } { E }_{ p }[f(\textbf{x})]\eqno{(17.2)} $$
 是将要估计的加和或者积分，我们把它重新写成一个期望，这里$p$是随机变量\(\textbf{x}\)的概率分布(对加和而言)或者概率密度(对积分而言)。
 
 我们可以通过从$p$中抽取$n$个样本 $ { \bm{x} }^{ (1) },...,{ \bm{x} }^{ (n) }$，然后构建下面的经验平均来估计$s$：
 $${ \hat { s }  }_{ n } =\frac { 1 }{ n } \sum _{ i=1 }^{ n }{ f({ \bm{x} }^{ (i) }) } .\eqno{(17.3)}$$
这种近似可以由几个不同的性质来证明。首先，我们通过观察可以发现\(\hat { { s } } \)是无偏的，因此
$$\mathbb{E}[\hat{s}_n]=\frac{1}{n}\sum_{i=1}^{n}\mathbb{E}[f(\bm{x}^{(i)})]=\frac{1}{n}\sum_{i=1}^{n}s=s \eqno{(17.4)}$$
但是除此之外，大数定律告诉我们如果样本\({ \bm{x} }^{ (i) }\)是独立同分布，那么几乎可以肯定该平均收敛于期望值：
$$\lim _{ n\rightarrow \infty  }{ { \hat { s }  }_{ n }= } s, \eqno{(17.5)}$$
条件是每一项的方差\(Var[f({ \bm{x} }^{ (i) })]\)是有界的。为了看的更清楚，考虑\(n\)递增时\({\hat { s }  }_{ n }\)的方差。只要
\(Var[f({ \textbf{x} }^{ (i) })]<\infty \)，方差\(Var[{ \hat { s }  }_{ n }]\)递减且收敛于0:
$$ Var[{ \hat { s } }_{ n }]=\frac { 1 }{ { n }^{ 2 } } \sum _{ i=1 }^{ n }{ Var[f(\textbf{x})] }  \eqno{(17.6)}$$
$$=\frac { Var[f(\textbf{x})] }{ n } . \eqno{(17.7)}$$
这个方便的结论也告诉了我们如何用蒙特卡罗平均估计不确定或者等价地蒙特卡罗近似的预期误差量。我们计算\(f({\bm{x}}^{ (i) })\)的经验平均\footnote{更常说方差的无偏估计量，其中平方误差和除以n-1而不是n。}和经验方差，然后用样本数量\(n\)来除估计的方差获得\(Var[{\hat { s }  }_{ n }]\)的估计。中心极限定理告诉我们分布的均值\({\hat { s }  }_{ n }\)收敛到均值为\(s\)，方差为\(\frac { Var[f(\bf{x})] }{ n } \)的正态分布。这使得我们能够使用正态密度的累计分布来估计\({\hat { s }  }_{ n }\)的置信区间。

然而所有这些依赖于我们能否很容易地从基本分布\(p(\bf{x})\)进行采样，但是我们可能并不能总是这样做。如果从\(p\)中采样不合理时，另一种方法是使用重要性采样，我们会在17.2节介绍它。一种更常用的方法是构造收敛到感兴趣的分布的估计序列，这种方法是蒙特卡罗马尔可夫链(见17.3节)。


\section{重要性采样}

在方程17.2中，蒙特卡罗方法使用的被积函数（或被加数）分解中，有一步很重要，那就是决定被积函数的哪部分应该作为概率分布\(p(\bm{x})\)，被积函数的哪部分应该作为其期望值(在概率分布下)被估计的数量函数\(f(\bm{x})\)。由于\(p(\bm{x})f(\bm{x})\)总是可以被写成
$$p(\bm{x})f(\bm{x})=q(\bm{x})\frac { p(\bm{x})f(\bm{x}) }{ q(\bm{x}) } ，\eqno{(17.8)}$$
所以被积函数没有唯一的分解。这里我们从\(q\)和均值\(\frac{pf}{q}\)进行抽样。在许多情况下，我们希望对于给定的\(p\)和\(f\)计算期望，并且从开始指定问题作为期望的事实表明这个\(p\)和\(f\)将是一种自然分解。但是就为了得到给定精度的准确率所需要的样本数量而言，问题的原始规范可能并不是最优的选择。幸运地是，最优选择\({ q }^{ * }\)的形式可以很容易地被推导出来。最优的\({ q }^{ * }\)对应于最优的重要性采样。

由于方程17.8中等式，任何蒙特卡罗估计：
$${ \hat { s }  }_{ p }=\frac { 1 }{ n } \sum _{ i=1,{ \bf{x} }^{ (i) }\sim  p }^{ n }{ f({ \bm{x} }^{ (i) }) } \eqno{(17.9)}$$
都可以被转换为重要性采样估计：
$${ \hat { s }  }_{ q }=\frac { 1 }{ n } \sum _{ i=1,{ \bf{x}}^{ (i) } \sim  q }^{ n }{ \frac { p({\bm{x}}^{ (i) })f({\bm{x}}^{ (i) }) }{ q({\bm{x}}^{ (i) }) }  } . \eqno{(17.10)}$$

我们可以很容易地看到估计的期望值不依赖于\(q\)：
$$\mathbb{E}_{ q }\left[ \hat { { s }_{ q } }  \right] =\mathbb{E}_{ q }\left[ \hat { { s }_{ p } }  \right] =s. \eqno{(17.11)}$$
但是，重要性采样估计的方差对\(q\)的选择非常敏感。方差由下式给出：
$$Var[\hat { { s }_{ q } } ]=Var[\frac { p(\bf{x})f(\bf{x}) }{ q(\bf{x}) } ]/n. \eqno{(17.12)}$$
当\(q\)取值如下的时候，可以使得方差最小：
$${ q }^{ * }(\bm{x})=\frac { p(\bm{x})|f(\bm{x})| }{ Z } , \eqno{(17.13)}$$
这里Z是正则化常数，它被用来使得\({ q }^{ * }(\bm{x})\)加和或者积分等于1。越好的重要性采样分布，在被积函数越大的地方，赋予的权重就越大。事实上，当\(f(\bm{x})\)不改变符号，\(Var[{ \hat { s }  }_{ { q }^{ * } }]=0\)，这意味着当我们使用最优分布时，单样本就足够了。当然，这只是因为\(q^{*}\)的计算基本上解决了原始问题，从最优分布中抽取一个单样本通常是不切实际的。
(从获得正确期望值的意义上来说)采样分布\(q\)的任何选择都是有效的，并且(从获得最小方差的意义上来说)\(q^{*}\)是最优的一个。从\(q^{*}\)中采样通常是不可行的，但是当我们继续减少方差，\(q\)的其他选择是可行的。

另一种方法是使用有偏的重要性采样，它的一个优势是不需要正则化的\(p\)或者\(q\)。在离散变量的情况下，有偏的重要性采样估计由下式给出：
$${ \hat { s }  }_{ BIS }=\frac { \sum _{ i=1 }^{ n }{ \frac { p({\bm{x}}^{ (i) }) }{ q({\bm{x}}^{ (i) }) }  } f({\bm{x}}^{ (i) }) }{ \sum _{ i=1 }^{ n }{ \frac { p({\bm{x}}^{ (i) }) }{ q({\bm{x}}^{ (i) }) }  }  } \eqno{(17.14)}$$
$$=\frac { \sum _{ i=1 }^{ n }{ \frac { p({\bm{x}}^{ (i) }) }{ \tilde { q } ({\bm{x}}^{ (i) }) }  } f({\bm{x}}^{ (i) }) }{ \sum _{ i=1 }^{ n }{ \frac { p({\bm{x}}^{ (i) }) }{ \tilde { q } ({\bm{x}}^{ (i) }) }  }  } \eqno{(17.15)}$$
$$=\frac { \sum _{ i=1 }^{ n }{ \frac { \tilde{p}({\bm{x}}^{ (i) }) }{ \tilde { q } ({\bm{x}}^{ (i) }) }  } f({\bm{x}}^{ (i) }) }{ \sum _{ i=1 }^{ n }{ \frac {\tilde {p}({\bm{x}}^{ (i) }) }{ \tilde { q } ({\bm{x}}^{ (i) }) }  }  }, \eqno{(17.16)}$$
这里\(\tilde {p}\)和\(\tilde {q}\)是\(p\)和\(q\)的无正则化形式，\({\bm{x}}^{ (i) }\)是\(q\)中的样本。因为\(\mathbb{E}\left[ \hat { { s }_{ BIS } }  \right] \neq s\)，该估计是有偏的，除了当\( n\rightarrow \infty\)，和方程17.14的分母收敛于1。因此这种估计被叫做渐进无偏的。

虽然\(q\)的一个好的选择可以极大地提高蒙特卡罗估计的效率，但是一个不好的选择会使得效率更差。回到方程17.12，我们可以看到如果\( \frac { p(\bm{x})|f(\bm{x})| }{ q(\bm{x}) } \)中的\(q\)的样本很大，那么估计的方差会变得非常大。这可能发生在\(q(\bm{x})\)很小，而\(p(\bm{x})\)和\(f(\bm{x})\)都不够小来抵消它时。\(q\)分布通常被选择为非常简单的分布以使得容易进行抽样。当\(\bm{x}\)是高维的，\(q\)的简单性会使得它对\(p\)或者\(p|f|\)的匹配非常糟糕。当\(q({\bm{x}}^{ (i) })\gg p({\bm{x}}^{ (i) })|f({\bm{x}}^{ (i) })\)，重要性采样会得到一些无用的样本(总和微小的数字或零)。另一方面，当\(q({\bm{x}}^{ (i) })\ll p({\bm{x}}^{ (i) })|f({\bm{x}}^{ (i) })\)，尽管这种情况更少发生，但是无用的样本比例会很大。由于后者的情况是极少的，它们可能不会出现在典型的样本中，产生s的典型低估，很少被大量过高估计补偿。所谓典型的，当\(\bm{x}\)是高维的，非常大或者非常小的数字就是典型的，因为在高维情况下，联合概率的动态范围是非常大的。

尽管存在上述危险，但是重要性采样和它的变种们在许多机器学习算法中都非常有用，包括深度学习算法。比如，使用重要性采样可以加速具有很大词汇表的神经语言模型，或者具有很多输出的其他神经网络的训练。另请参考18.7章节重要性采样是如何被用来估计配分函数(概率分布的正则化常数)的，和20.10.3章节重要性采样是如何被用来估计深度有向模型，比如变分自编码器的对数似然的。重要性采样可以被用来改进代价函数的梯度估计，该代价函数被用来训练使用随机梯度下降的模型的参数，特别是对于诸如分类器的模型，其中代价函数的大部分总值来自很少量的被分错的样本。更频繁地抽样更困难的例子可以减少这种情况下梯度的方差（Hinton，2006）。
